{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd021b14e6ae810b98687c42101764fbc6ed2f749f10b37141b42930ea65db4f89b",
   "display_name": "Python 3.6.12 64-bit ('drlnd': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\danie\\anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:109.)\n  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# --- Load Agents --- #\n",
    "from agent_reinforce.agent import REINFORCEAgent\n",
    "from agent_deepqn.agent import DeepQAgent\n",
    "from agent_ddpg.agent import DDPG_Agent\n",
    "\n",
    "# --- Load Environments --- #\n",
    "from environment.grid import GridEnv\n",
    "\n",
    "# --- Load Necessary --- #\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from utilities.helper import flatten\n",
    "\n",
    "\n",
    "# --- Load Training --- #\n",
    "from training import train\n",
    "from experiment import Experiment\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridEnv(num_agent = 1, agents_start = [(1,1)], goals_start=[(7,7)])\n",
    "agents = [DeepQAgent(env.state_space, env.action_space.n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environments = [GridEnv(num_agent = 1, agents_start = [(1,1)], goals_start=[(7,7)]), GridEnv(num_agent = 3)]\n",
    "wrapped_agents = [[DeepQAgent(env.state_space, env.action_space.n) for n in range(env.num_agent)] for env in environments]\n",
    "\n",
    "print(wrapped_agents)\n",
    "print(environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Not all _agents_ have fixed starting positions, rest (2) will be random\nNot all _goals_ have fixed starting positions, rest (2) will be random\n"
     ]
    }
   ],
   "source": [
    "environments = [GridEnv(num_agent = 2)]\n",
    "wrapped_agents = [[DeepQAgent(env.state_space, env.action_space.n) for n in range(env.num_agent)] for env in environments]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments=[Experiment(\"Test Experiment\", env, agents, max_t=1, num_episodes=1) for agents, env in zip(wrapped_agents, environments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running experiment\n",
      "Encountered an error, going to log into file\n",
      "Ran experiments\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "get_constant_string() missing 1 required positional argument: 'config'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2cda67f57991>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mscores_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\danie\\Code\\ai\\udacity-nano\\research company\\multi-taxi-drl\\experiment.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, score_history, state_history, options, display, scores_window)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'scores'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'figures'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'states'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores_window\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;34m'scores'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msave_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'states'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#save_states(score_history)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mrender_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgoal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgoal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'figures'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores_window\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscores_window\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\Code\\ai\\udacity-nano\\research company\\multi-taxi-drl\\utilities\\monitor.py\u001b[0m in \u001b[0;36msave_scores\u001b[1;34m(scores, config, path)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfor_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_constant_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}Scores_{}_{}.csv\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y-%m-%d_%H%M\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfor_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_constant_string() missing 1 required positional argument: 'config'"
     ]
    }
   ],
   "source": [
    "for experiment in experiments:\n",
    "    scores_history, state_history = experiment.run()\n",
    "    experiment.save(scores_history, state_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}