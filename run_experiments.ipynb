{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd021b14e6ae810b98687c42101764fbc6ed2f749f10b37141b42930ea65db4f89b",
   "display_name": "Python 3.6.12 64-bit ('drlnd': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\danie\\anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:109.)\n  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# --- Load Agents --- #\n",
    "from agents.agent_reinforce.agent import REINFORCEAgent\n",
    "from agents.agent_deepqn.agent import DeepQAgent\n",
    "from agents.agent_ddpg.agent import DDPG_Agent\n",
    "\n",
    "# --- Load Environments --- #\n",
    "from environment.grid import GridEnv\n",
    "\n",
    "# --- Load Necessary --- #\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from utilities.helper import flatten\n",
    "\n",
    "\n",
    "# --- Load Training --- #\n",
    "from experiments.experiment import Experiment\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "source": [
    "# Generalized"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environments = [GridEnv(num_agent = 2, agents_start = [(1,1)], goals_start=[(7,7)]), GridEnv(num_agent = 2)]\n",
    "wrapped_agents = [[DeepQAgent(env.state_space, env.action_space.n) for n in range(env.num_agent)] for env in environments]\n",
    "# wrapped_agents = [[DeepQAgent(env.state_space, env.action_space.n, dddpqagent_config) for n in range(env.num_agent)] for env in environments]\n",
    "\n",
    "# dddpqagent_config=[{}, ]\n",
    "# print(environments)\n",
    "# print(wrapped_agents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_experiments=[Experiment(\"Test Experiment\", env, agents, max_t=100, num_episodes=300) for agents, env in zip(wrapped_agents, environments)]\n",
    "\n",
    "# dqn_experiments=[Experiment(\"Test Experiment\", env, agents, max_t=100, num_episodes=300) for agents, env in zip(wrapped_agents, environments)]\n",
    "\n",
    "# reinforce_experiments=[Experiment(\"Reinforce Experiment\", env, agents, max_t=100, num_episodes=300) for agents, env in zip(wrapped_agents, environments)]\n",
    "\n",
    "# print(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in ddpg_experiments:\n",
    "    score_history, state_history = experiment.run()\n",
    "    experiment.save(score_history, state_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination=np.array(np.meshgrid(num_players, agents_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "#print(combination.T)\n",
    "import itertools\n",
    "print(len(list(itertools.product(*configs))))\n",
    "# for r in itertools.product(num_players, agents_start):\n",
    "#     for q in itertools.product(r, goals_start):\n",
    "#         for s in itertools.product(q, prob_right_direction):\n",
    "#             print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}